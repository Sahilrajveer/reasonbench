% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/evaluate_model.R
\name{evaluate_model}
\alias{evaluate_model}
\title{Evaluate Model Against Realistic Benchmarks}
\usage{
evaluate_model(
  df,
  target_col,
  pred_col,
  dist = "poisson",
  extra_params = list(),
  n_sim = 20L,
  seed = 123L
)
}
\arguments{
\item{df}{Data frame containing target and prediction columns.}

\item{target_col}{Character. Target variable name.}

\item{pred_col}{Character. Model predictions column name.}

\item{dist}{Character. Distribution family for the simulation.}

\item{extra_params}{List. Extra distribution parameters.}

\item{n_sim}{Integer. Number of simulations.}

\item{seed}{Integer. Random seed.}
}
\value{
Tibble summarizing MAE, MSE, and R² for each benchmark.
}
\description{
Compares a model’s predictive performance against three reference points:
\enumerate{
\item No-skill model (predicting the mean),
\item Reasonably-perfect model (simulated stochastic baseline),
\item The model itself.
}
}
